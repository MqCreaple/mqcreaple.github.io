---
title: 社会科学中定量研究的诸多问题
layout: blog
tags: ["social-science", "math"]
---

刚刚结束了今年的IMMC比赛（某个数学建模比赛），这次的题目是社会科学相关，使用了很多定量研究方法。由于比赛在现在还没有结束，就不透露任何和比赛题目相关的问题了。我们队这次比赛之前几乎都没有任何社会科学背景，尤其是对定量研究方法很不熟悉，导致比赛中途我们改了很多次模型都没拿到期望的结果。在这里我想简单写一下从这次比赛里我收获的一些知识。

## 定量研究

量化研究，具体就是指对某个需要研究的量建立一个**可以衡量的指标**，并用**统计、数学、计算**等方法去对这个指标做分析。这个名词通常作为**定性研究**的反义词。在一个定量研究中，通常的步骤是：建立指标，收集数据，预处理数据，分析数据。定量研究通常更客观，你可以说一切现代科学都建立在对这个世界的定量研究上。

我们发现，许多社会科学领域已经有十分成熟的定量研究方法了，比如在经济学中就有例如GDP这样的衡量一个经济体的指标。在医学中~~虽然医学严格来说不是社会科学~~，许多曾经无法定量研究的量也随着科技进步变得可以测量了，比如血常规就可以用来测量一个人身体各项指标是否正常。

即使是在统计学如此发达的今天，仍然有很多问题是我们无法衡量的，尤其是涉及人的主观情绪和观点的学科，如心理学、社会学、政治学。例如，我们（至少目前）没有任何一个能够准确测量一个人性格的指标——不论是MBTI还是哪些其他的性格量表都只能描述某个人性格的一个侧面。

如果一个定量研究设计得不好，还有可能产生负面社会影响。例如美国军方最早用来测量智商的“Alpha and Beta Test”其中就包含了许多白人中产阶级才有了解的题目，如保龄球、网球、唱片机等，这让出身少数族裔的无产阶级群体在做同一套智商测试的时候得到的分数普遍更低，而这个分数差异也被科学家用来合理化歧视少数族裔。

这不禁让我们想：既然定量研究更客观，为什么社会科学里面的定量研究就会有如此多的问题？定量的研究真的比定性研究更好吗？

## 哲学层面：哪些东西是能量化的？为什么能量化？

在现代的度量单位发明之前，这其实是一个困扰了哲学家很久的问题，比如亚里士多德就曾讨论过现实世界与数学世界的联系。

### “测量”到底是什么

科学哲学家普遍认为，“测量”本质上是一个将现实世界中的物体与正实数建立对应的这样一个过程。我们以**长度**这一量度为例。一个物体的长度具有如下几条性质：

1. 定类（$=$, $\ne$）：如果两个物体A与B并排放置之后发现A和B两端对齐，那么用长度测量A和B就会得到相同的数。
1. 定序（$\gt$, $\lt$）：如果将A与B并排放置，一端对齐，发现A的另一端比B更长，那么使用长度来测量A得到的数值就会比B更大。
1. 定距（$-$）：如果物体A与物体B首尾相接之后和物体C一样长，那么物体B的长度就可以表示成物体A和C长度的差。
1. 定比（$\div$）：如果$n$个物体A首尾相接后和物体B一样长，那么物体B的长度就是物体A的$n$倍。

可以看到，有了这几条性质之后，再加上一个长度的标准度量衡（比如统一使用国际标准米尺作为$1$单位的长度），我们就可以唯一确定一个从“所有物体”到“所有正实数”之间的映射，即一个度量衡。

所有的度量衡都满足这四条性质吗？并不是，比如我们再来看**温度**，这里我们考虑摄氏温标（℃）而非热力学温标（K）：

1. 定类（$=$, $\ne$）：如果两个物体A和B处于热平衡，那么A和B的摄氏温标相同。
1. 定序（$\gt$, $\lt$）：如果两个物体A和B放在一起，热量从A向B传导，那么A的摄氏温标比B大。
1. 定距（$-$）：如果我们加热一个物体A，不论其起始温度是多少，如果向其传输的热量是一样的，那么这个物体在加热之后的摄氏温标与加热之前的摄氏温标的差距一样。即：把一杯水从20℃加热到50℃的能量和同一杯水从45℃加热到75℃的能量一样大。

但注意，摄氏度没有“定比”属性。你不能说20℃的水就比10℃的水热2倍。虽然此时我们仍然可以把物体温度映射到一个实数上面，但这时两个物体温度的比值就没有意义。

再比如说，测量矿物硬度的时候可能会用到**莫氏硬度(Mohs scale)**。它就是一个只能“定类”和“定序”，而不能“定距”和“定比”的度量。

1. 定类（$=$, $\ne$）：如果两个物体A和B相互刻划，两者都有轻微划痕，则两个物体的硬度相同。
2. 定序（$\gt$, $\lt$）：如果两个物体A和B相互刻划，A上没有划痕而B上有划痕，那么A的硬度比B大。

莫氏硬度使用了10种不同的矿物来标记硬度的10个级别，但莫氏硬度的数值不能做加减法——它只能用来标记两个矿物硬度的相对关系，而它不保证3级硬度和2级硬度的差与2级硬度和1级硬度的差相同。

### 社会科学的量表

如果说上面三个自然科学中使用的量表都是有一个比较直观的定类和定序的方法，那么绝大部分社会科学探讨的问题都是无法定序，甚至无法定类的，比如**智商**。

智商，顾名思义就是测量一个人智力的量表。可是“智力”这个概念本身就没有一个良好的定义。大众或许对“哪个人更聪明”有一个大概的了解，但由于人与人之间的能力和知识差异太大了，你很难说哪两个人“同等聪明”。或许诸葛亮比张飞更聪明，但诸葛亮和爱因斯坦谁更聪明？这个问题本身就没有意义，因为“运筹帷幄”需要的的智力和“洞察世界”需要的智力本身就很难相互比较。或者说，“智商”这个概念本身就不是能“定类”的，更不要说定序和定量了。

那么在此基础上发明出来的“智商测试”，就必定是对一个复杂概念——智商——简化后的结果。比如我们常见的标准智商测试题通常都是这样的找规律题：

![Raven Matrix](/img/Raven-Matrix-sample.svg)*莱文方阵（来源：wikipedia）*

如果一个人做这样的题比另一个人得分更高，你能说这个人就比另一个人聪明吗？取决于你怎么定义“智商”。“智商”这个概念其实是片面的，人的智力水平是不能简单归结于做智商测试题的能力。

当然也不是所有社会学研究的问题都不能定量，也有许多能够定量描述的社会学参量：经济学里面的收入、存款等等涉及和“财富”相关的量就可以被量化，心理学里一个人脑内激素和神经递质水平也可以相对准确地描述一个人的情绪。这里我主要针对的是使用问卷和量表等“看起来很客观”的测量方式对一个主观概念做定量分析的研究方法，比如上文提到的智商测试，又或者是最近非常流行的MBTI人格测试这些。

## 数据准确性：定量研究真的更客观吗？

通常我们认为一个科学客观的标准应当符合以下这几条要求：

1. 客观：研究结果不应该包含研究者自己的个人经验和情感
1. 可复制：别的研究者可以使用同样的研究方法研究同样的问题而得到相同的结果

但一个定量社会科学研究真的能做到这两点吗？或许，符合这些要求的研究并不多。抛开在收集数据过程中可能出现的各类误差（如：无反应误差）不谈，光是“怎么定量”就问题重重。

### 提问方式

在很多情况下，对于同一个问题，不同的提问方式可能会带来显著的回答差异，大到用统计学方法能明显地看出区别。比如，在某个研究里面，当问及受试者“你是否幸福”的时候，用-5到5做答案区间的话就会比用0到10做答案区间得到的结果换算到同一个区间之后更高 [1]。类似的例子还有很多。

你也可以说，是语言和文字这一媒介导致了“问卷”很难获得客观的回答。使用问卷调查的时候，调查者从读到问题再到给出回复，这个过程都需要经过文字→思想→文字这一过程，而这两个转换的过程会受到很多环境和心理层面的其他因素干扰。研究者至多能让题目不带任何主观情绪，但很难减少受试者在阅读和理解题目时候的误差。这样的“量化”真的不以主观意志而转移吗？

在定量研究里，**提出一个合理的问题比用统计方法分析数据更为重要**。

### “黑白化”

另一个宏观社会学研究中无法避免的问题就是需要“黑白化”一个“灰色”的答案。为了能够量化答案，受试者必须把自己的答案给强行塞到“是”/“否”这样的二元回答或者是0~10这样的评分里，而真实的回答可能远远没有这么简单。

例如，如果某项研究在调查不同家庭的宠物数量，这项研究就很难推广到农村里——牲畜是否应当算作宠物？看门狗是否算作宠物？农村里人与动物的关系与城市中大不相同，因此即便有两个研究组研究同一个问题，对“宠物”这个概念的定义不同也可能导致完全不同的数据。类似地，“到底什么样的行为算劳动”这一问题的不同回答可能会导致计算出来差别巨大的失业率数据。

有时候为了定量研究，我们不得不把一些不能定量的概念给强行定量，例如前文里“智商”这个例子。一个略微好一点的方法是将一个不可比较的概念分解成多个相互独立且更能比较的概念，比如把“智商”分解成“数学能力”、“语言能力”等不同的维度，在每个维度上分别用问卷等形式测量出其得分。但另一方面，划分维度的方法是完全主观的，比如某个人可能认为“数学能力”和“语言能力”就可以完全覆盖“智商”这个概念，但另一个人可能认为“语言能力”需要进一步分成“语法能力”和“修辞能力”，还有人可能认为“记忆能力”也是智商的一部分。

> 引申问题：如果一个社群中的所有成员都认同某个标准（比如“谦虚是一种美德”）而某项研究采用了这个标准（比如把一个人的谦虚程度作为衡量人情商的一部分），这项研究是客观的吗？
>
> 以自然科学的标准来看的话，那么这项研究就不是客观的，因为这些标准都是社会建构的：在不同的文化里面有可能谦虚就不一定是美德，有可能不同的文化和社群对“谦虚”的重视程度不一样。这也是为什么**一项社会科学的研究永远不能脱离它研究的时代、文化和群体**。

## 解读数据

统计学固然在分析宏观数据分布和趋势时非常有用，但只关注统计数据而忽略掉无法统计的因素也会出问题。维基百科上有一条名为[麦克马拉谬误](https://en.wikipedia.org/wiki/McNamara_fallacy)的条目，又称“量化谬误”，指的是过度相信统计数据而忽略了统计数据之外的其他因素对某个变量的影响。

这种过度量化也逐渐渗透到了现代生活的方方面面：网上购物时只关注评分而不关注物品本身的价值和属性，投资时只考虑回报率而不关注资金背后的过程，甚至于在大公司招聘时要用试题给求职者打分。若我们都只关注数据，而不去思考这些数据怎么来的、背后的意义是什么，那么就很容易被数据误导。

## 相关性 vs. 因果性

即使上述所有误差我们都尽可能地避免，最终得到的数据也保证尽可能准确，仍然还有从*观测*到*决策*这一步。自然科学里面你的观测数据不会影响到自然本身的运行，但在社会科学里，你的观测数据和你对数据的解读是会切实影响到其他人的决策。一个国家的经济可能真的会因为研究者预测其会增长而真的逐渐增长。此时，为了能让研究结果在付诸实践的时候产生尽可能小的负面影响，准确区分两个变量的*相关性*和*因果性*就显得格外必要。

出于伦理道德的要求和人性的约束，社会科学里很难做大规模实验，而只用对比观察得出的结论很难区分两个变量到底仅仅是*相关*还是有*因果关系*。若两个变量没有因果关系，而是某个（或多个）隐藏变量导致了两者，又或者仅仅是巧合，那么实施政策的一方试图改变第一个变量时就不一定会达到预期的效果，反而有可能产生意想不到的影响。关于相关性和因果性的讨论在统计学里面应该已经老生常谈了，我在此也不多赘述。

> 其实“统计学”这门学科的来源并不是很干净——最早的统计学方法除了用在统计国家的经济数据以外，也被用来合理化种族歧视、优生学、甚至于种族灭绝。B站up[长河劫](https://space.bilibili.com/35868098)的[这个视频](https://www.bilibili.com/video/BV1KS421P7sN/)就讲了这一段历史。我认为，每一个从事社会研究的人都应该从这段历史中学到一件事：**科学方法不能让人失去人性**。这一点在研究人类自身的社会科学里尤其重要。

## 人工智能时代的展望

近几年的机器学习技术发展的十分迅猛，尤其是大语言模型让机器拥有了阅读和生成人类文字的能力。这也不禁让我思考：机器学习以及其衍生的基于大数据的统计模型是否能够在社会科学中发挥出更大的作用？虽然目前还没有看到太大的势头，但我猜测应该会的。

相比于传统的统计模型，机器学习相关的模型能够更好地处理复杂概念和抓住大量数据背后的关联。这在社会科学调查里的应用潜力很大。比如，我们现在不仅能对问卷里的选择题和评分题做统计分析，还可以用大语言模型对包含文字内容的简答题做统计分析了。再比如，无监督学习模型可以用来量化一系列事物之间的复杂关系，比如词语之间的关联程度和人际关系的连接强度。

另一方面，机器学习方法也无法完全避免上述的问题，像是过度依赖定量和统计。机器学习方法也有一些其独有的局限性：由于机器学习完全依赖喂给它的数据，如果这些数据里面有系统性的偏差，那么模型训练出来也会包含这些偏差。像是我最近在看的一本书《人机对齐》（*The Alignment Problem*）里面所说的，由于人类社会中对特定职业的性别偏见（比如通常认为程序员是男性，护士是女性），用大量人类语料训练出来的word2vec程序里面就会把特定职业和特定性别联系起来，而如果此时某个相关职业的机构（如：互联网公司）使用word2vec算法来筛选求职者的简历，导致筛选出来的简历里男性多于女性，就会进一步加剧性别刻板印象。

有关人工智能相关的社会学问题太多了，社会各界也对此各执一词。这个话题我可以以后多写一些文章来讨论。

## 总结

社会科学的研究对象和研究问题是复杂的，不同的研究方法都只能像盲人摸象一样看到社会不同的侧面，定量研究也不例外。本文主旨不在于完全否定一切定量研究，而是指出定量研究、统计方法和机器学习等方法存在的问题，避免陷入数据崇拜和机器学习崇拜。

本文主要讨论了人本主义的观点：一个人存在的意义不应该只是成为一串数字里的一个“1”。不同的社会科学学派可能对此意见不一，但所有社会科学学派都认同一件事：“人”本身就是一个复杂的存在，而由许多人建构起的社会则只会更加复杂。科学方法和定量研究给了我们一个研究这个社会十分有力的工具，但这个工具终究不完美。未来的社会科学会如何发展还需要静待时间的考验。

## 参考资料

[1] Schwarz, N. (1999). *Self-reports: How the questions shape the answers*. American Psychologist, 54(2), 93–105. <https://doi.org/10.1037/0003-066X.54.2.93>

[2] Christian, Brian. *The Alignment Problem: Machine Learning and Human Values*. Norton & Company, 2020. 
